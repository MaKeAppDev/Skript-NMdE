\chapter{Numerische Infinitesimalrechnung}

\section{Numerisches Differenzieren}

\begin{equation}
	f'(x_0) = \lim\limits_{h\rightarrow 0} \frac{f(x_0 + h) - f(x_0)}{h}
\end{equation}

Taylor-Polynom: \[ f(x_0 + h) = f(x_0) + h\cdot f'(x_0) + \frac{h^2}{2} \cdot f''(x_0) + \frac{h^3}{3}\cdot f^{(3)}(x_0) + \ldots\]
Abbruch nach linearem Term: \[f(x_0+h) = f(x_0) + h\cdot f'(x_0) + R(h^2)\]

"'Vorwärtsdifferenz"':
\begin{equation}
	f'(x_0) = \frac{f(x_0 + h) - f(x_0)}{h} + R(h)
\end{equation}

"'Rückwärtsdifferenz:"'
\begin{equation}
	f(x_0 - h) = f(x_0) - h \cdot f(x_0) + \frac{h^2}{2} \cdot f''(x_0) - \ldots
\end{equation}

\subsection{Fehleranalyse}
Zentrierte Differenz $f'(x_0) = \frac{f(x_0+h) - f(x_0-h)}{2h} - \frac{f^{(3)}(\xi)}{6}h^2$\\
Rundungsfehler:
\begin{equation}
\begin{split}
f(x_0+h) &= \underset{\text{gerundeter Wert}}{\tilde{f}(x_0-h)} + e_{-1}\\
f(x_0-h) &= \tilde{f}(x_0+h) + e_{+1}
\end{split}
\end{equation}
\begin{equation}
f'(x_0) = \frac{\tilde{f}(x_0+h) - \tilde{f}(x_0-h)}{2h} + \frac{e_{+1} - e_{-1}}{2h} - \frac{f^{(3)}(\xi)}{6}h^2
\end{equation}
Annahmen: $\abs{e_{-1}},\abs{e_{+1}} \leq\varepsilon$ und $\abs{f^{(3)}(\xi)} \leq M$\\
Damit $\abs{f'(x_0) - \frac{\tilde{f}(x_0+h) - \tilde{f}(x_0-h)}{2h}} \leq\frac{\varepsilon}{h} + \frac{h^2M}{6}$\\
$\Rightarrow h_{\text{opt}} = \sqrt[3]{\frac{3\xi}{M}}$

\section{Numerische Integration}
Alternativer Begriff: "`Numerische Quadratur"' (bestimmte Integrale)

\subsection{Newton-Cotes-Ansätze}
\begin{equation}
\begin{split}
J &= \int\limits_a^bf(x)\diff x \cong\int\limits_a^bP_h(x)\diff x\\
P_n(x) &= a_0 + a_1x + \ldots + a_nx^n
\end{split}
\end{equation}

\begin{figure}
	\center
	\begin{subfigure}{0.3\textwidth}
		\input{figures/newton_cotes_linear}
		\caption{Polynom 1. Ordnung}
	\end{subfigure}
	\begin{subfigure}{0.3\textwidth}
		\input{figures/newton_cotes_quadratisch}
		\caption{Polynom 2. Ordnung}
	\end{subfigure}
	\begin{subfigure}{0.3\textwidth}
		\input{figures/newton_cotes_multi}
		\caption{mehrere Polynome}
	\end{subfigure}
	\caption{Unterschiedliche Methoden eine Funktion bei einer numerischen Integration anzunähern}
\end{figure}

\subsubsection{Trapezregel}
Lineares Lagrange Polynom
\begin{equation}
\begin{split}
P_1(x) &= \frac{x-x_1}{x_0-x_1}\cdot f(x_0) + \frac{x-x_0}{x_1-x_0}\cdot f(x_1)\\
\int\limits_a^b &= \int\limits_{x_0}^{x_1}P_1(x)\diff x + \underbrace{\frac{1}{2}\int\limits_{x_0}^{x_1}f''(\xi(x))\cdot (x-x_0)\cdot (x-x_1)\diff x}_{x_1 \text{Fehlerterm}}\\
 & \text{Mittelwert Integralrechnung}\\
 &= \frac{1}{2}f''(\xi)\int\limits_{x_0}^{x_1}(x-x_0)\cdot (x-x_1)\diff x = \frac{1}{2}f''(\xi)\left[\frac{x^3}{3}-\frac{(x_1+x_0)}{2}x^2+x_0x_1x\right]_{x_0}^{x_1} = \frac{-h^3}{12}f''(\xi)
\end{split}
\end{equation}
mit $h = b-a = x_1-x_0$

Also:
\begin{equation}
\int\limits_a^bf(x)\diff x = \left[\frac{(x-x_1)^2}{2(x_0-x_1)}\cdot f(x_0) + \frac{(x-x_0)^2}{2(x_1-x_0)}\cdot f(x_1)\right]_{x_0}^{x_1} - \frac{h^3}{12}f''(\xi) = \frac{h}{2}\left[f(x_0) + f(x_1)\right] - \frac{h^3}{12}f''(\xi)
\end{equation}
Exakt, sofern $f(x)$ höchstens linear ist

\subsubsection{Simpson Regel}
Quadratisches Lagrange Polynom
\begin{equation}
\begin{split}
\int\limits_a^bf(x)\diff x &= \int\limits_{x_0}^{x_2}\frac{(x-x_1)(x-x_2)}{(x_0-x_1)(x_0-x_2)}f(x_0) + \frac{(x-x_0)(x-x_2)}{(x_1-x_0)(x_1-x_2)}f(x_1) + \frac{(x-x_0)(x-x_1)}{(x_2-x_1)(x_2-x_1)}f(x_2)\diff x\\ &+ \int\limits_{x_0}^{x_2}\frac{(x-x_0)(x-x_1)(x-x_2)}{6}f^{(3)}(\xi(x))\diff x\\
&= \frac{h}{3}\left[f(x_0)+4f(x_1)+f(x_2)\right]-\frac{h^5}{90}f^{(4)}(\xi)
\end{split}
\end{equation}
mit $h=x_1-x_0 = x_2-x_1$

\paragraph{Simpson $\frac{3}{8}$ Regel}
\begin{equation}
\int\limits_a^bf(x)\diff x = \frac{3h}{8}\left[f(x_0)+3f(x_1)+3f(x_2)+f(x_3)\right]-\frac{h^5}{6480}f^{(4)}(\xi)
\end{equation}
\begin{itemize}
\item benötigt $3m$ Segmente bzw. $3m+1$ Stützpunkte
\item Grad der Genauigkeit/"`Degree of precision"'\\
Größte ganze Zahl $n$, so dass eine Integrationsformel für $x^k,\; k=0,1,\ldots,n$ exakte Resultate liefert.
\end{itemize}

\paragraph{Composite Simpson $\frac{1}{3}$}
Teile $[a,b]$ in $n$ Teilintervalle auf. Wende die Simpson Regel auf jedes Paar nacheinanderfolgender Teilintervalle an.\\
$h = \frac{b-a}{n}$; $x_j=a+j\cdot h$, $j=0,1,\ldots ,n$
\begin{equation}
\begin{split}
\int\limits_a^bf(x)\diff x &= \sum_{j=1}^{\frac{n}{2}}\int\limits_{x_{2j-2}}^{x_{2j}}f(x)\diff x\\
&= \sum_{j=1}^{\frac{n}{2}}\frac{h}{3}\left[f(x_{2j-2})+4f(x_{2j-1})+f(x_{2j})\right]\frac{h^5}{90}f^{(4)}(\xi_j)\\
&= \frac{h}{3}\left[f(x_0)+2\sum_{j=1}^{\frac{n}{2}-1}f(x_{2j}) + 4\sum_{j=1}^{\frac{n}{2}}f(x_{2j-1} + f(x_n)\right] - \frac{h^5}{90}\sum_{j=1}^{\frac{n}{2}}f^{(4)}(\xi_0)
\end{split}
\end{equation}
mit $x_{2j-2} < \xi_j y x_{2j}, f$ auf $[a,b]$ 4-mal stetig differenzierbar.

\paragraph{Fehler} $E(f) = \frac{-h^5}{90}\sum_{j=1}^{\frac{n}{2}}f^{(4)}(\xi_j)$, mit $x_{2j-2} < \xi_j y x_{2j}, j=1,2,\ldots,\frac{n}{2}$

\paragraph{Extremwertsatz}: $f^{(4)}$ nimmt Max und Min auf $[a,b]$ an, also
\begin{equation}
\begin{split}
\min\limits_{x\in[a,b]}f^{(4)}(x) \leq f^{(4)}(\xi_j) \leq \max\limits_{x\in[a,b]}f^{(4)}(x)\\
\frac{n}{2}\min\limits_{x\in[a,b]}f^{(4)}(x) \leq \sum_{j=1}^{\frac{n}{2}}f^{(4)}(\xi_j) \leq \frac{n}{2}\max\limits_{x\in[a,b]}f^{(4)}(x)\\
\min\limits_{x\in[a,b]}f^{(4)}(x) \leq \frac{n}{2}\sum_{j=1}^{\frac{n}{2}}f^{(4)}(\xi_j) \leq \max\limits_{x\in[a,b]}f^{(4)}(x)
\end{split}
\end{equation}

\paragraph{Zwischenwertsatz} Es existiert ein $\mu\in(a,b)$, so dass
\begin{equation}
f^{(4)}(\mu) = \frac{2}{n}\sum_{j=1}^{\frac{n}{2}}f^{(4)}(\xi_j)
\end{equation}
Damit
\begin{equation}
E(f) = \frac{-h^5}{90}\sum_{j=1}^{\frac{n}{2}}f^{(4)}(\xi_j) = \frac{-h^5}{180}n\cdot f^{(4)}(\mu) \overset{h=\frac{b-a}{n}}{=} \frac{-(b-a)}{180}h^4\cdot f^{(4)}(\mu)
\end{equation}

Also, mit $\mu \in (a, b)$:
\begin{equation}
	\int_a^b f(x) \diff x = \frac{h}{3} \left[ f(a) + 2 \sum_{j = 1}^{n/2 - 1} f(x_{2j} + 4 \sum_{j = 1}^{n/2} f(x_{2j - 1}) + f(b) \right] - \frac{b - a}{180} h^4 f^{(4)}(\mu)
\end{equation}

Wie man sich nun vielleicht vorstellen kann gibt es unendlich viele mögliche numerische Integrationsverfahren. Das Composite Simpson-Verfahren ist allerdings ein häufig eingesetztes allgemeines Verfahren.

\subsection{Genauigkeit}
Zur Bestimmung der Genauigkeit gibt es zwei Ansätze:
\begin{enumerate}
	\item Gegeben sei ein Verfahren, eine Funktion $f$, ein Interval $[a, b]$ und eine Stützstellenanzahl $n$ und gesucht sei der Fehler
	\item Gegeben sei eine Funktion $f$, ein Interval $[a, b]$ und ein gewünschter Fehler und gesucht sei ein Verfahren und eine Stützstellenanzahl $n$
\end{enumerate}

Der Rundungsfehler wird definiert über
\begin{equation}
	f(x_i) = \underbrace{\tilde{f}(x_i)}_{\text{gerundeter Wert}} + \underbrace{e_i}_{\text{Rundungsfehler}}
\end{equation}

Damit erhält man dann einen akkumulierten Fehler $e(h)$ bei Composite-Simpson von
\begin{equation}
	e(h) = \left| \frac{h}{3} \left[ e_0 + 2 \sum_{j = 1}^{n/2 - 1} e_{2j} + 4 \sum_{j = 1}^{n/2} e_{2j - 1} + e_n \right] \right| \le \frac{h}{3} \left[ |e_0| + 2 \sum_{j = 1}^{n/2 - 1} |e_{2j}| + 4 \sum_{j = 1}^{n/2} |e_{2j - 1}| + |e_n| \right]
\end{equation}
Seine alle Rundungsfehler $|e_i| \le \epsilon$, dann gilt
\begin{equation}
	e(h) \le \frac{h}{3} \left[ \epsilon + 2(\frac{n}{2} - 1) \epsilon + 4 \frac{n}{2} \epsilon + \epsilon \right] = n h \epsilon = (b - a) \epsilon \ne f(h, n)
\end{equation}
Erstaunlich ist somit, dass der Rundungsfehler nicht wächst, wenn der zu integrierende Bereich in mehr Teilintervalle unterteilt wird. 

\section{Numerische Lösung von DGLen}
Bsp: Einschwinganalyse (TRansiente Analyse)

\missingfigure{schaltung}

\subsection{Analytische Lösung mittels Laplace-Transformation}
\begin{equation}
\begin{split}
C\cdot\dot{y}(t) + \frac{1}{R}\cdot y(t) &= i_0(t)\\
\dot{y}(t) + \underbrace{\frac{1}{RC}}_{-p_\infty}\cdot y(t) &= \frac{1}{RC}R\cdot i_0(t)\\
\dot{y}(t) - p_\infty y(t) &= -p_\infty R\cdot i_0(t)\\
\LT \text{Laplace}\\
p\cdot Y(p) - \underbrace{y(+0)}_{=0} - p_\infty Y(p) &= -p_\infty R\frac{1}{p}\cdot I_0\\
Y(p) &= \frac{-p_\infty R\cdot I_0}{(p-p_\infty)} = \frac{A}{p} + \frac{B}{p-p_\infty}
\end{split}
\end{equation}
\begin{equation}
A = \lim\limits_{p\rightarrow 0} p\cdot Y(p) = R\cdot I_0
\end{equation}
\begin{equation}
B = \lim\limits_{p\rightarrow p_\infty} (p-p_\infty)\cdot Y(p) = -R\cdot I_0
\end{equation}
\begin{equation}
\begin{split}
\LT\\
y(t) = A + B e^{p_\infty t} = R\cdot I_0\cdot (1-e^{p_\infty t})
\end{split}
\end{equation}

\subsection{Numerische Lösung mittels explizite Euler-Methode (linear Z-Transformation)}
\missingfigure{plot}
Diskretisierung der Zeit 
\begin{equation}
y(\nu)\hat{=} y(\nu\cdot\Delta t) = y(t)
\end{equation}
Diskretisierung der DGL 
\begin{equation}
\dot{y}(\nu)\approx p_\infty\cdot y(\nu) - p_\infty - p_\infty R\cdot i_0(\nu)
\end{equation}
Differenzengleichung (explizite Euler-Methode)
\begin{equation}
y(\nu+1)\approx y(\nu) + \Delta t\cdot\dot{y}(\nu)
\end{equation}

\missingfigure{plot}
\begin{equation}
y(\nu+1)\approx y(\nu) + \Delta t\cdot\left[p_\infty y(\nu) - p_\infty R\cdots i_0(\nu)\right]\quad ,\nu = 0,1,2,\ldots
\end{equation}
\begin{equation}
\hat{y}(\nu+1) = (1+p_\infty\Delta t)\cdot y(\nu) - \Delta t p_\infty R i_0(\nu)
\label{eq:y_dach}
\end{equation}
sukzessive Berechnung ausgehend von $y(0),\;\nu = 1,2,3,\ldots$

Bei linearen Schaltungen (linearen Differenzengleichungen) ist geschlossene numerische Lösung möglich durch $\ZT$ von \autoref{eq:y_dach}
\begin{equation}
z\cdot\dot{Y}(z)-\underbrace{z\cdot y(0)}_{0} - (1-p_\infty\Delta t)\cdot Y(z) = -p_\infty R\Delta t \frac{z}{z-1}I_0
\end{equation}
\begin{equation}
\begin{split}
Y(z) &= \frac{-p_\infty\Delta t R}{z-(1+p_\infty\Delta t)}\frac{zI_0}{z-1} = \frac{zRI_0}{z-1}\frac{zRI_0}{z-(1+p_\infty\Delta t)}\\
\ZT\\
\hat{y}(\nu) &= \left[1-(1+p_\infty\Delta t)^\nu\right]\cdot RI_0\quad ,\nu = 0,1,2,\ldots
\end{split}
\end{equation}

Zahlenbeispiel: $I_0R = 1;\;p_\infty = -1,\; t=1$\\
exakte Lösung: $y(1) = 1-e^{-1} = \num{0.632121}$\\
numerische Lösung: $y(\nu) = 1-(1-\Delta t^\nu\quad ,\nu\cdot\Delta t = 1$

\begin{tabular}{c|c|c|c}
$\Delta t$ & $\nu$ & $\dot{y}(1)$ & $\varepsilon^{(A)} = \abs{\hat{y}(1)-y(1)}$\\
\hline
\num{0.1} & \num{10} & \num{0.651322} & \num{0.019201}\\
\num{0.05} & \num{20} & \num{0.641514} & \num{0.009393}\\
\num{0.025} & \num{40} & \num{0.636768} & \num{0.004647}\\
\end{tabular} 
$\quad$ Fehler $\varepsilon^{(A)}\sim \Delta t$