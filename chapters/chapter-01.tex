\chapter{Einführung}
\label{chap:einfuehrung}

\section{Zusammenfassung}

\subsection{Überblick}
\begin{figure}
	\center
	\input{figures/mathematik_teilgebiete}
	\caption{Teilgebiete der Mathematik}
\end{figure} 

\textbf{Definitionsversuch:} Entwicklung und mathematisches Verständnis von numerischen Algorithmen, als von Rechenmethoden zur zahlenmäßigen Lösung mathematischer Probleme.

\textbf{Zusammenspiel mit Informatik:}
\begin{figure}
	\input{figures/zusammenspiel_mathematik_informatik}
	\caption{Zusammenspiel Mathematik und Information in der Numerik}
\end{figure}

\subsection{Vorgehen}
\begin{figure}
	\center
	\input{figures/loesung_mathematisches_problem}
	\caption{Vorgehen zur Lösung eines mathematischen Problems}
\end{figure}

\subsection{Aspekte für die Lösung einer mathematischen Aufgabenstellung}
\begin{itemize}
	\item Kondition eines Problems (Empfindlichkeit für Störungen)
	\item Numerische Lösungsverfahren
	\item Stabilität des Lösungsverfahrens (Empfindlichkeit für Störungen)
	\item Effizienz des Lösungsverfahrens
	\item Genauigkeit der Lösung
\end{itemize}

\section{Wiederholung}

\subsection{Lineares Gleichungssystem}

\begin{align}
	a_{11}\,x_1 + \ldots + a_{1n}\,x_n &= b_1\\
	a_{21}\,x_1 + \ldots + a_{2n}\,x_n &= b_2\\
	&\vdots\\
	a_{m1}\,x_1 + \ldots + a_{mn}\,x_n &= b_m\\
	\ma{A} \cdot \vec{x} &= \vec{b}\\
	\ma{A} &\in \mathbb{R}^{m\times n},\ \vec{x} \in \mathbb{R}^n,\ \vec{b} \in \mathbb{R}^m
\end{align}

\subsection{Matrizen}
\subsubsection{Elementare Matrix-Operationen}

\paragraph{Addition}
\begin{align}
	\ma{A}_{<m\times n>} + \ma{B}_{<m\times n>} &= \ma{C}_{<m\times n>}\\
	c_{\mu\nu} &= a_{\mu\nu} + b_{\mu\nu}
\end{align}

\paragraph{Multiplikation mit Skalar}
\begin{align}
	k \cdot \ma{A} = \ma{A} \cdot k = B\\
	b_{\mu\nu} = k \cdot a_{\mu\nu}
\end{align}

\paragraph{Matrix-Multiplikation}
\begin{align}
	\ma{A}_{<m\times n>} \cdot \ma{B}_{<n\times l>} &= \ma{C}_{<m\times l>}\\
	c_{\mu\nu} &= \sum_{\nu=1}^{n} a_{\mu\nu} \cdot b_{\mu\lambda};\quad \mu=1\ldots m,\ \lambda=1\ldots l
\end{align}

\paragraph{Multiplikation Matrix-Vektor}
\begin{align}
	\text{Spezialfall der Matrix-Multiplikation: } <n\times 1> \text{ bzw. } <1\times n>
\end{align}

\paragraph{Auffassen als Linearkombination der Spalten der Matrix}
\begin{align}
	\ma{A} \cdot \vec{x} &= \vec{b}\\
	\begin{bmatrix}\vec{a}_1 & \vec{a}_2 & \ldots & \vec{a}_n\end{bmatrix} \cdot \vec{x} &= \vec{b}\\
	\vec{a}_1\,\vec{x} + \ldots + \vec{a}_n\,\vec{x}_n &= \vec{b}
\end{align}

\paragraph{Vektoren}
\begin{align}
	\text{Spaltenvektor:} \quad & \vec{a}_{<n\times 1>}: \vec{a}\\
	\text{Zeilenvektor:} \quad & \vec{b}_{<1\times m>}^T: \vec{b}^T
\end{align}

\paragraph{Vektormultiplikation}
\begin{align}
	\vec{b}^T\cdot \vec{a} &= c \quad \text{(Skalarprodukt $m=n$!)}\\
	\vec{a} \cdot \vec{b}^T &= \ma{C} \quad \text{(Vektorprodukt, dyadisches Produkt)}
\end{align}

\paragraph{Matrix als Kombination von Zeilen- und Spaltenvektoren}
\begin{align}
	\ma{A}_{<m\times n>} &= \begin{bmatrix} \vec{a}_1^T \\ \vec{a}_2^T \\ \vdots \\ \vec{a}_m^T \end{bmatrix}\\
	\ma{B}_{<n\times l>} &= \begin{bmatrix} \vec{b}_1 & \vec{b}_2 & \ldots & \vec{b}_l \end{bmatrix}\\
	\ma{A} \cdot \ma{B} &= \ma{C}\\
	\vec{c}_{\mu\lambda} &= \vec{a}_\mu^T \cdot \vec{b}_\lambda
\end{align}

\paragraph{Rechenregeln}
\begin{align}
	\left(\ma{A}\cdot \ma{B}\right)\cdot \ma{C} &= \ma{A} \cdot \left(\ma{B} \cdot \ma{C}\right) \quad \text{Assoziativität}\\
	\ma{A} \cdot \left(\ma{B} + \ma{C}\right) &= \ma{A}\,\ma{B} + \ma{A}\,\ma{B} \quad \text{Distributivität}\\
	\ma{A} \cdot \ma{B} &\neq \ma{B} \cdot \ma{A} \quad \text{Kumutativität gilt im Allgemeinen nicht}
\end{align}

\paragraph{Diagonalmatrix}
\begin{align}
	\ma{D} &= \text{diag}\begin{bmatrix}d_1 & d_2 & \ldots & d_n\end{bmatrix} = \begin{bmatrix}d_1 & \ldots & 0 \\ 0 & \ldots & d_n\end{bmatrix}\\
	\ma{D}_1 \cdot \ma{D}_2 &= \ma{D}_2 \cdot \ma{D}_1
\end{align}

\paragraph{Einheitsmatrix}
\begin{align}
	\ma{I} = \ma{E} = \ma{1} = \text{diag}\begin{bmatrix}1 & \ldots & 1\end{bmatrix}\\
	\ma{A} \cdot \ma{I} = \ma{I} \cdot \ma{A}\\
	\ma{I}^n = \ma{I}\\
	\ma{I}^{-1} = \ma{I}
\end{align}

\paragraph{Transponierte Matrix}
\begin{align}
	\ma{A}_{<m\times n>}^T &= \ma{B}_{<n\times m>},\ b_{\nu\mu} = a_{\mu\nu}\\
	\left(\ma{A} \cdot \ma{B}\right)^T &= \ma{B}^T \cdot \ma{A}^T\\
	\ma{A} &= \ma{A}^T \quad \Rightarrow \text{ symmetrische Matrix}
\end{align}

\paragraph{Inverse Matrix}
\begin{align}
	\ma{A} &\in \mathbb{R}^{n\times n}\\
	\ma{A}^{-1} \cdot \ma{A} &= \ma{A} \cdot \ma{A}^{-1} = \ma{I}\\
	\text{$\ma{A}^{-1}$ existiert nur für nicht singuläre $\ma{A}$}&\text{ und ist eindeutig.}\\
	\ma{A} = \text{diag}\begin{bmatrix}d_1 & \ldots & d_n\end{bmatrix} & \Rightarrow \ma{A}^{-1} = \text{diag}\begin{bmatrix}\frac{1}{d_1} & \ldots & \frac{1}{d_n}\end{bmatrix}\\
	\left(\ma{A} \cdot \ma{B}\right) &= \ma{B}^{-1} \cdot \ma{A}^{-1}
\end{align}

\subsubsection{Matrix- und Vektornormen}

\[||\cdot||:\ \mathbb{R}^n \rightarrow \mathbb{R};\ \mathbb{R}^{n\times n} \rightarrow \mathbb{R}\]\\
Bedingungen für \textbf{Vektornormen}:
\begin{itemize}
	\item \[||\vec{x}|| \geq 0,\ ||\vec{x}|| = 0 \text{ nur für } \vec{x} = \vec{0}\]
	\item \[||c \cdot\vec{x}|| = \abs{c} \cdot ||\vec{x}||,\ c \in \mathbb{R}\]
	\item \[||\vec{x} + \vec{y}|| \leq ||\vec{x}|| + ||\vec{y}||\] Dreiecksungleichung
\end{itemize}

Bedingungen für \textbf{Matrixnormen}:
\begin{itemize}
	\item \[||\ma{A}|| \geq 0,\ ||\ma{A}|| = 0 \text{ nur für } \ma{A} = \ma{0}\]
	\item \[|| c \cdot \ma{A}|| = \abs{c} \cdot ||\ma{A}||,\ c \in \mathbb{R}\]
	\item \[||\ma{A} + \ma{B}|| \leq ||\ma{A}|| + ||\ma{B}||\]
	\item \[||\ma{A} \cdot \ma{B}|| \leq ||\ma{A}|| \cdot ||\ma{B}||\] Multiplikativitätsbedingung
	\item \[||\ma{A} \cdot \vec{x}|| \leq ||\ma{A}|| \cdot ||\vec{x}||\] Kompatibilitätsbedingung
\end{itemize}

\paragraph{Vektornormen} \hfill \\
\begin{tabular}{r@{ = }ll}
	$\norm{\vec{x}}_1$ & $\sum\limits_{i=1}^n\abs{x_i}$ & Betragssummennorm, $l_1$-Norm\\
	$\norm{\vec{x}}_2$ & $\sqrt{\sum\limits_{i=1}^n\abs{x_i}^2}$ & Euklidnorm, $l_2$-Norm, Vektorlänge\\
	$\norm{\vec{x}}_\infty$ & $\underset{i}{\max}{\abs{x_i}}$ & Maximumsnorm, $l_\infty$-Norm, Tschebychefnorm\\
	$\norm{\vec{x}}_p$ & $\sqrt[p]{\sum\limits_{i=1}^n\abs{x_i}^p}$, $p\geq 1$ & Höldernormnorm, $l_p$-Norm
\end{tabular}

\paragraph{Matrixnormen $(A\in\mathbb{R}^{n\times n})$} \hfill \\
\begin{tabular}{r@{ = }ll}
	$||\ma{A}||_M$ & $n\cdot\underset{i,j}{\max}\abs{a_{ij}}$ & Gesamtnorm, Matrixnorm $(||\ma{I}|| = n)$\\
	$(||\ma{A}||_\infty = )||\ma{A}||_Z$ & $\underset{i}{\max}\sum\limits_{j=1}^n\abs{a_{ij}}$ & Zeilennorm $(||\ma{I}||_Z = 1)$\\
	$(||\ma{A}||_1 = )||\ma{A}||_S$ & $\underset{j}{\max}\sum\limits_{i=1}^n\abs{a_{ij}}$ & Spaltennorm $(||\ma{I}||_S = 1)$\\
	$||\ma{A}||_E$ & $\sqrt{\sum\limits_{i=1}\sum\limits_{j=1}\abs{a_{ij}}^2}$ & Euklidnorm, Schurnorm, Frobeniusnorm $(||\ma{I}||_E = \sqrt{n})$\\
	$(\ma{A}||_\lambda = )||\ma{A}||_\lambda$ & $\sqrt{\lambda_\text{max}(\ma{A}^T \ma{A})}$ & Spektralnorm, Hilbertnorm $(||\ma{I}||_\lambda = 1)$\\
\end{tabular}

\paragraph{Kompatibilität zwischen Vektor und Matrixnorm} \hfill \\
\begin{tabular}{r@{\hspace{0.7cm}}l}
	$l_1$ : & $||\ma{A}\vec{x}||_1 \leq ||\ma{A}||_M\cdot||\vec{x}||_1$\\
	& $||\ma{A}\vec{x}||_1 \leq ||\ma{A}||_S\cdot||\vec{x}||_1$\\
	$l_2$ : & $M,\lambda,E$\\
	$l_\infty$ : & $M,Z$\\
\end{tabular}

\section{Schaltungsanalyse}
\begin{figure}
	\center
	\input{figures/schaltung_beispiel_1}
	\caption{Beispielschaltung}
\end{figure}
\begin{tabular}{llll}
	\textcolor{green!70!blue}{$\vec{i}_{<k>}$} & \textcolor{green!70!blue}{Kantenstromvektor} & \textcolor{blue}{$\vec{u}_{<k>}$} & \textcolor{blue}{Kantenspannungsvektor}\\
	$\vec{i}_{0<k>}$ & Kantenquellenstromvektor & $\vec{u}_{0<k>}$ & Kantenquellenspannungsvektor\\
	$\vec{i}_{n<k>}$ & Knotenquellenstromvektor & \textcolor{red}{$\vec{u}_{n<k>}$} & \textcolor{red}{Knotenquellenspannungsvektor}\\
	\\
	$\ma{A}_{<n\times k>}$ & Kontenmatrix, Knoteninzidenzmatrix & &\\
	$\ma{Y}_{<k\times k>}$ & Kantenadmittanzmatrix & &\\
	$\ma{Y}_{n<n\times n>}$ & Kontenadmittanzmatrix & &\\
\end{tabular}

\subsection{Gerichteter Graph der Schaltung}

\subsection{Inzidenz Matrix}
\begin{align}
	\ma{A}_{<m\times n>} = \begin{bmatrix}
	1 & & & -1\\
	 & 1 & & -1\\
	-1 & & 1 & \\
	 & & 1 & -1\\
	 & -1 & 1 & 
	\end{bmatrix}
\end{align}
Summen der Spaltenvektoren $= \vec{0}$.\\
$\Rightarrow \ma{A}$ hat linear abhängige Spalten.

Rang der Matrix $\ma{A}$: $r = \rang{\ma{A}} = 3 = n-1$.\\
Dimension des Nullraums: Zahl der Spalten $-\ r = 1$ .\\
Vektor im Nullraum von $\ma{A}$:
\begin{align}
	\ma{A}\cdot\vec{u}=\vec{0}\Rightarrow\vec{u}\in ;\quad\vec{u}=\begin{bmatrix}1\\1\\1\\1\end{bmatrix}
\end{align}

\subsection{Laplace Matrix}
\begin{align}
	\ma{A}^T\cdot\ma{A} = \begin{bmatrix}
	1 & 0 & -1 & 0 & 0\\ 
	0 & 1 & 0 & 0 & -1 \\ 
	0 & 0 & 1 & 1 & 1 \\ 
	-1 & -1 & 0 & -1 & 0
	\end{bmatrix}\cdot\begin{bmatrix}
	1 & 0 & 0 & -1 \\ 
	0 & 1 & 0 & -1 \\ 
	-1 & 0 & 1 & 0 \\ 
	0 & 0 & 1 & -1 \\ 
	0 & -1 & 1 & 0
	\end{bmatrix} = \begin{bmatrix}
	2 & 0 & -1 & -1 \\ 
	0 & 2 & -1 & -1 \\ 
	-1 & -1 & 3 & -1 \\ 
	-1 & -1 & 3 & -1
	\end{bmatrix}  
\end{align}
\begin{itemize}
	\item singulär
	\item $r = 3$
	\item symmetrisch
\end{itemize}
\begin{align}
	\ma{A}^T\cdot\ma{A} = \underset{\text{Grad (degree)}}{\ma{D}} - \underset{\text{Adjazenz}}{\ma{W}} = \begin{bmatrix}
	2 & 0 & 0 & 0 \\ 
	0 & 2 & 0 & 0 \\ 
	0 & 0 & 3 & 0 \\ 
	0 & 0 & 0 & 3
	\end{bmatrix} - \begin{bmatrix}
	0 & 0 & 1 & 1 \\ 
	0 & 0 & 1 & 1 \\ 
	1 & 1 & 0 & 1 \\ 
	1 & 1 & 1 & 0
	\end{bmatrix} 
\end{align}

\subsection{Kirchhoffsches Stromgesetz (KCL)}

\begin{tabular}{lll}
	$\ma{A}^T\cdot \vec{w} = \vec{0}$ & (keine Stromquellen) & $\vec{w}$: Kantenströme\\
	$\ma{A}^T\cdot \vec{w} = \vec{f}$ & (mit Stromquellen) & $\vec{f}$: Stromquellen
\end{tabular}

\subsection{Ohmsches Gesetz}
\begin{tabular}{ll}
	$\vec{w} = \ma{C} \cdot \vec{e}$ & $\ma{C}$: Diagonalmatrix der Kantenleitwerte\\
	 & $\vec{e}$: Kantenspannungen
\end{tabular}

\subsection{Kirchhoffsches Spannungsgesetz (KVL)}
\begin{tabular}{ll}
	$\vec{e} = \vec{b} - \ma{A} \cdot \vec{u}$ & $\vec{u}$: Kantenspannungen - GESUCHT\\
	 & $\vec{b}$: Spannungsquellen
\end{tabular}

\begin{align}
	\ma{A}^T \cdot \vec{w} = \vec{f}\\
	\ma{A}^T \cdot \ma{C} \cdot \vec{e} = \vec{f}\\
	\ma{A}^T \cdot \ma{C} \left( \vec{b} - \ma{A}\cdot\vec{u}\right) = \vec{f}\\
	\underset{\text{Systemmatrix, gewichtete Laplace Matrix}}{\ma{A}^T \cdot \ma{C} \cdot \ma{A}} \cal \vec{u} = \ma{A}^T \cdot \ma{C} \cdot \vec{b} \cdot \vec{f}\\
	\ma{Y}_{<n\times n>} \cdot \vec{u}_{<n>} = \vec{d}_{<n>}
\end{align}

singulär $\Rightarrow$ nicht invertierbar\\
$\Rightarrow$ keine Lösung für Gleichungssystem\\
Abhilfe: Festlegung eines Bezugspunktes, z.B. $u_0 = 0$\\
\ldots

\subsection{Alternative Darstellung}
\begin{align}
	\ma{C}^{-1} \cdot \vec{w} + \ma{A} \cdot \vec{u} &= \vec{b}\\
	\ma{A}^T \cdot \vec{w} = \vec{f}\\
	\begin{bmatrix}
	\ma{C}^{-1} & \ma{A} \\ \ma{A}^T & \ma{0}\end{bmatrix} \cdot \begin{bmatrix}\vec{w} \\ \vec{w}\end{bmatrix} = \begin{bmatrix}\vec{b}\\\vec{f}\end{bmatrix}
\end{align}

\section{Maschinendarstellung von Zahlen}
(IEEE 754-2008-"'Binary Floating Point Arithmetic Standard"')\\
Darstellung reeller Zahlen: 64 bit:\\
\begin{tabular}{lll}
	s & 1 bit & Vorzeichen\\
	c & 11 bit & Exponent\\
	f & 52 bit & Mantisse
\end{tabular}

\[ x = (-1)^s \cdot 2 ^{c-1023}\cdot (1 + f)\]

z.B.: 
\begin{align}
	10:& \underbrace{0}_{s} \quad \underbrace{100000000010}_{c:\ 1026-1023=3}\quad\underbrace{0100\ldots010}_{f:\ \num{1.25}}\\
	\num{-0.8}:& \underbrace{1}_{s} \quad \underbrace{01111111110}_{c:\ 1022-1023=-1}\quad\underbrace{10011001\ldots10011010}_{f:\ \num{1.59999}}
\end{align}

\subsection{Gleitkomma-Arithmetik: Eigenschaften und Fehlerarten}
$x$: beliebige reelle Zahl (mathematisch exakt)\\
$z_1,\,z_2$: Gleitkomma-Maschinenzahlen (endliche Stellenzahl)\\
\textbf{Gl}eitkomma - Grund\textbf{op}erationen\\
$\text{gl}(z_1\, \text{op}\, z_2)$,\quad op := $+$, $-$, $\times$, $/$
\begin{enumerate}[label=\alph*)]
	\item $z_1 \, \text{op}\, z_2 = x;$ \quad $x$ nicht notwendigerweise Gleitkomma-Maschinenzahl
	\item $+,\ -$: Exponentenangleich erforderlich - Mantissenstellen können verloren gehen.
	\item Subtraktion nahezu gleichgroßer Zahlen:
		\begin{itemize}
			\item Ergebnis mit wesentlich kleinerer Mantisse
			\item Normalisierung (Linksverschiebung Mantisse, Exponentenangleich): Nachziehen nicht signifikanter Ziffern, Verlust signifikanter Ziffern
		\end{itemize}
	\item Unterlauf/Überlauf
\end{enumerate}

\ldots